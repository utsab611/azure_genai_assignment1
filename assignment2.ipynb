{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5483a2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install pypdf faiss-cpu --quiet\n",
    "!python -m pip install langchain langchain-core langchain-community langchain-experimental --quiet\n",
    "!python -m pip install langchain-openai --quiet\n",
    "!python -m pip install langchain-community langchainhub langchain-chroma langchain langchain-experimental --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423c35b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded 25 documents\n",
      "\n",
      " Refined Query: Search query: \"recommended courses after Python Programming for Data Science focusing on data visualization\"\n",
      "\n",
      " Final Recommended Courses:\n",
      "['Data Visualization with Python', 'Advanced Data Visualization Techniques', 'Introduction to Machine Learning', 'Data Analysis with Pandas', 'Statistics for Data Science']\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# from typing import List\n",
    "# from pydantic import BaseModel\n",
    "# from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "# from langchain.prompts import ChatPromptTemplate\n",
    "# from langchain.output_parsers import PydanticOutputParser\n",
    "# from langchain.chains import LLMChain\n",
    "# from langchain_community.document_loaders import CSVLoader\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# from langchain_chroma import Chroma\n",
    "# import ast\n",
    "\n",
    "\n",
    "# # ======================================================\n",
    "# # 1. Define Recommendation Model\n",
    "# # ======================================================\n",
    "# class Recommendation(BaseModel):\n",
    "#     courses: List[str]\n",
    "\n",
    "\n",
    "# parser = PydanticOutputParser(pydantic_object=Recommendation)\n",
    "\n",
    "# # ======================================================\n",
    "# # 2. Load CSV and Create Vector DB\n",
    "# # ======================================================\n",
    "# file_path = \"/home/zadmin/Desktop/GAAI-B4-Azure/datasets/assignment2dataset.csv\"\n",
    "# loader = CSVLoader(file_path=file_path, encoding=\"utf-8\")\n",
    "# docs = loader.load()\n",
    "\n",
    "# print(f\" Loaded {len(docs)} documents\")\n",
    "\n",
    "# # Split text into chunks\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "# splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# # Embeddings\n",
    "# embedding_model_name = \"text-embedding-3-small\"\n",
    "# embeddings = AzureOpenAIEmbeddings(\n",
    "#     model=embedding_model_name,\n",
    "#     azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "# )\n",
    "\n",
    "# # Vector DB\n",
    "# vector_db_path = \"VectorDB_Chroma_asssignment2\"\n",
    "# os.makedirs(vector_db_path, exist_ok=True)\n",
    "\n",
    "# vectorstore = Chroma.from_documents(\n",
    "#     documents=splits,\n",
    "#     embedding=embeddings,\n",
    "#     persist_directory=vector_db_path,\n",
    "#     collection_name=\"Trainings\",\n",
    "#     collection_metadata={\"use_type\": \"TRAINING AND EXPERIMENTATION\"}\n",
    "# )\n",
    "\n",
    "# retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})\n",
    "\n",
    "\n",
    "# # ======================================================\n",
    "# # 3. LLM Setup\n",
    "# # ======================================================\n",
    "# llm = AzureChatOpenAI(\n",
    "#     deployment_name=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\", \"gpt-4o-mini\"),\n",
    "#     model=\"gpt-4o\",\n",
    "#     temperature=0\n",
    "# )\n",
    "\n",
    "# # ======================================================\n",
    "# # 4. Query Refinement Step\n",
    "# # ======================================================\n",
    "# query_refine_prompt = ChatPromptTemplate.from_messages([\n",
    "#     (\"system\", \"You are a helpful assistant that reformulates user queries \"\n",
    "#                \"into concise search queries for retrieving training materials.\"),\n",
    "#     (\"human\", \"User question: {question}\")\n",
    "# ])\n",
    "\n",
    "# query_refine_chain = LLMChain(\n",
    "#     llm=llm,\n",
    "#     prompt=query_refine_prompt\n",
    "# )\n",
    "\n",
    "# # ======================================================\n",
    "# # 5. Recommendation Step\n",
    "# # ======================================================\n",
    "# recommendation_prompt = ChatPromptTemplate.from_messages([\n",
    "#     (\"system\",\n",
    "#      \"You are an AI assistant that recommends exact 5 training courses. \"\n",
    "#      \"Use the retrieved context about available trainings to suggest courses. \"\n",
    "#      \"Return the results strictly in JSON format.\"),\n",
    "#     (\"human\",\n",
    "#      \"Original Question: {question}\\n\\n\"\n",
    "#      \"Retrieved Context:\\n{context}\\n\\n\"\n",
    "#      \"{format_instructions}\")\n",
    "# ])\n",
    "\n",
    "# recommendation_chain = LLMChain(\n",
    "#     llm=llm,\n",
    "#     prompt=recommendation_prompt,\n",
    "#     output_parser=parser\n",
    "# )\n",
    "\n",
    "\n",
    "# # ======================================================\n",
    "# # 6. Pipeline Function\n",
    "# # ======================================================\n",
    "# def run_pipeline(question: str) -> List[str]:\n",
    "#     # Step 1: Refine query\n",
    "#     refined_query = query_refine_chain.run({\"question\": question}).strip()\n",
    "#     print(f\"\\n Refined Query: {refined_query}\")\n",
    "\n",
    "#     # Step 2: Retrieve context from vectorstore\n",
    "#     docs = retriever.get_relevant_documents(refined_query)\n",
    "#     context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "#     # Step 3: Final recommendation\n",
    "#     result = recommendation_chain.invoke({\n",
    "#         \"question\": question,   # original question\n",
    "#         \"context\": context,\n",
    "#         \"format_instructions\": parser.get_format_instructions()\n",
    "#     })\n",
    "\n",
    "#     return result\n",
    "\n",
    "\n",
    "# # ======================================================\n",
    "# # 7. Example Run\n",
    "# # ======================================================\n",
    "# if __name__ == \"__main__\":\n",
    "#     query = \"“I’ve completed the ‘Python Programming for Data Science’ course and enjoy data visualization. What should I take next?”\"\n",
    "#     courses = run_pipeline(query)\n",
    "#     s=str(courses['text'])\n",
    "#     print(\"\\n Final Recommended Courses:\")\n",
    "#     # Extract the part inside courses=[...]\n",
    "#     start = s.find(\"[\")\n",
    "#     end = s.find(\"]\", start) + 1\n",
    "\n",
    "#     courses_list = ast.literal_eval(s[start:end])\n",
    "#     print(courses_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e39505f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded 25 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5135/1026446952.py:87: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  query_refine_chain = LLMChain(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing recommend_courses function ===\n",
      "Top 5 recommendations with similarity scores:\n",
      "  C016 - Python Programming for Data Science: 0.5562\n",
      "  C014 - Data Visualization with Tableau: 0.4586\n",
      "  C011 - Big Data Analytics with Spark: 0.4325\n",
      "  C017 - R Programming and Statistical Analysis: 0.4286\n",
      "  C004 - Computer Vision and Image Processing: 0.4001\n",
      "=== EVALUATION REPORT ===\n",
      "\n",
      "--- Test Profile 1 ---\n",
      "Input: I've completed the 'Python Programming for Data Science' course and enjoy data visualization. What should I take next?\n",
      "Completed Courses: ['C001']\n",
      "Vector-based Recommendations (Course ID, Similarity Score):\n",
      "  C016 - Python Programming for Data Science: 0.5687\n",
      "  C014 - Data Visualization with Tableau: 0.4555\n",
      "  C017 - R Programming and Statistical Analysis: 0.4330\n",
      "  C011 - Big Data Analytics with Spark: 0.4320\n",
      "  C004 - Computer Vision and Image Processing: 0.4304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5135/1026446952.py:153: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  refined_query = query_refine_chain.run({\"question\": question}).strip()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Refined Query: \"Advanced Data Visualization courses for Python\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5135/1026446952.py:157: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(refined_query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM-enhanced Recommendations:\n",
      "  C002 - Deep Learning with TensorFlow and Keras\n",
      "  C003 - Natural Language Processing Fundamentals\n",
      "  C004 - Computer Vision and Image Processing\n",
      "  C005 - Reinforcement Learning Basics\n",
      "  C006 - Data Engineering on AWS\n",
      "\n",
      "Relevance Comments: Both methods provide semantically relevant course recommendations.\n",
      "\n",
      "--- Test Profile 2 ---\n",
      "Input: I know Azure basics and want to manage containers and build CI/CD pipelines. Recommend courses.\n",
      "Completed Courses: []\n",
      "Vector-based Recommendations (Course ID, Similarity Score):\n",
      "  C007 - Cloud Computing with Azure: 0.5723\n",
      "  C009 - Containerization with Docker and Kubernetes: 0.5063\n",
      "  C008 - DevOps Practices and CI/CD: 0.4853\n",
      "  C006 - Data Engineering on AWS: 0.4186\n",
      "  C025 - MLOps: Productionizing Machine Learning: 0.3796\n",
      "\n",
      " Refined Query: \"Azure container management and CI/CD pipeline courses\"\n",
      "LLM-enhanced Recommendations:\n",
      "  C008 - DevOps Practices and CI/CD\n",
      "\n",
      "Relevance Comments: Both methods provide semantically relevant course recommendations.\n",
      "\n",
      "--- Test Profile 3 ---\n",
      "Input: My background is in ML fundamentals; I'd like to specialize in neural networks and production workflows.\n",
      "Completed Courses: ['C001']\n",
      "Vector-based Recommendations (Course ID, Similarity Score):\n",
      "  C025 - MLOps: Productionizing Machine Learning: 0.4702\n",
      "  C002 - Deep Learning with TensorFlow and Keras: 0.3981\n",
      "  C003 - Natural Language Processing Fundamentals: 0.3839\n",
      "  C005 - Reinforcement Learning Basics: 0.3588\n",
      "  C004 - Computer Vision and Image Processing: 0.3551\n",
      "\n",
      " Refined Query: Search query: \"neural networks specialization courses production workflows\"\n",
      "LLM-enhanced Recommendations:\n",
      "  C002 - Deep Learning with TensorFlow and Keras\n",
      "  C003 - Natural Language Processing Fundamentals\n",
      "  C004 - Computer Vision and Image Processing\n",
      "  C005 - Reinforcement Learning Basics\n",
      "  C006 - Data Engineering on AWS\n",
      "\n",
      "Relevance Comments: Both methods provide semantically relevant course recommendations.\n",
      "\n",
      "--- Test Profile 4 ---\n",
      "Input: I want to learn to build and deploy microservices with Kubernetes—what courses fit best?\n",
      "Completed Courses: []\n",
      "Vector-based Recommendations (Course ID, Similarity Score):\n",
      "  C009 - Containerization with Docker and Kubernetes: 0.6290\n",
      "  C007 - Cloud Computing with Azure: 0.4720\n",
      "  C010 - APIs and Microservices Architecture: 0.4681\n",
      "  C008 - DevOps Practices and CI/CD: 0.4340\n",
      "  C019 - Agile and Scrum Mastery: 0.3974\n",
      "\n",
      " Refined Query: \"Courses on building and deploying microservices with Kubernetes\"\n",
      "LLM-enhanced Recommendations:\n",
      "  C009 - Containerization with Docker and Kubernetes\n",
      "\n",
      "Relevance Comments: Both methods provide semantically relevant course recommendations.\n",
      "\n",
      "--- Test Profile 5 ---\n",
      "Input: I'm interested in blockchain and smart contracts but have no prior experience. Which courses do you suggest?\n",
      "Completed Courses: []\n",
      "Vector-based Recommendations (Course ID, Similarity Score):\n",
      "  C023 - Blockchain Technology and Smart Contracts: 0.5571\n",
      "  C024 - Augmented and Virtual Reality Development: 0.3270\n",
      "  C021 - Cybersecurity Fundamentals: 0.3166\n",
      "  C022 - Internet of Things (IoT) Development: 0.3103\n",
      "  C013 - NoSQL Databases and MongoDB: 0.2985\n",
      "\n",
      " Refined Query: \"beginner blockchain and smart contracts courses\"\n",
      "LLM-enhanced Recommendations:\n",
      "  C023 - Blockchain Technology and Smart Contracts\n",
      "\n",
      "Relevance Comments: Both methods provide semantically relevant course recommendations.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "from pydantic import BaseModel\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "import ast\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 1. Define Recommendation Model\n",
    "# ======================================================\n",
    "class Recommendation(BaseModel):\n",
    "    courses: List[str]\n",
    "\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Recommendation)\n",
    "\n",
    "# ======================================================\n",
    "# 2. Load CSV and Create Vector DB\n",
    "# ======================================================\n",
    "file_path = \"/home/zadmin/Desktop/GAAI-B4-Azure/datasets/assignment2dataset.csv\"\n",
    "loader = CSVLoader(file_path=file_path, encoding=\"utf-8\")\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\" Loaded {len(docs)} documents\")\n",
    "\n",
    "# Load the CSV with pandas to get course IDs\n",
    "df = pd.read_csv(file_path)\n",
    "course_ids = df['course_id'].tolist()\n",
    "titles = df['title'].tolist()\n",
    "descriptions = df['description'].tolist()\n",
    "\n",
    "# Split text into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Embeddings\n",
    "embedding_model_name = \"text-embedding-3-small\"\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    model=embedding_model_name,\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    ")\n",
    "\n",
    "# Vector DB\n",
    "vector_db_path = \"VectorDB_Chroma_asssignment2\"\n",
    "os.makedirs(vector_db_path, exist_ok=True)\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=vector_db_path,\n",
    "    collection_name=\"Trainings\",\n",
    "    collection_metadata={\"use_type\": \"TRAINING AND EXPERIMENTATION\"}\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 10})\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 3. LLM Setup\n",
    "# ======================================================\n",
    "llm = AzureChatOpenAI(\n",
    "    deployment_name=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\", \"gpt-4o-mini\"),\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# ======================================================\n",
    "# 4. Query Refinement Step\n",
    "# ======================================================\n",
    "query_refine_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that reformulates user queries \"\n",
    "               \"into concise search queries for course recommendations. \"\n",
    "               \"Focus on extracting key skills, technologies, and learning objectives \"\n",
    "               \"from the user's profile and interests.\"),\n",
    "    (\"human\", \"User profile and interests: {question}\")\n",
    "])\n",
    "\n",
    "query_refine_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=query_refine_prompt\n",
    ")\n",
    "\n",
    "# ======================================================\n",
    "# 5. Recommendation Step\n",
    "# ======================================================\n",
    "recommendation_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are an AI course recommendation assistant. Based on the user's profile and the retrieved course information, \"\n",
    "     \"recommend exactly 5 most relevant courses. Consider the user's completed courses, interests, and career goals. \"\n",
    "     \"Return only the course IDs (like C001, C002, etc.) in JSON format. Exclude any courses the user has already completed.\"),\n",
    "    (\"human\",\n",
    "     \"User Profile: {question}\\n\\n\"\n",
    "     \"Completed Courses: {completed_courses}\\n\\n\"\n",
    "     \"Available Courses Context:\\n{context}\\n\\n\"\n",
    "     \"{format_instructions}\")\n",
    "])\n",
    "\n",
    "recommendation_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=recommendation_prompt,\n",
    "    output_parser=parser\n",
    ")\n",
    "\n",
    "# ======================================================\n",
    "# 6. Core Assignment Function - FIXED for actual course IDs\n",
    "# ======================================================\n",
    "def recommend_courses(profile: str, completed_ids: List[str]) -> List[Tuple[str, float]]:\n",
    "    \"\"\"\n",
    "    Returns a list of (course_id, similarity_score) for the top-5 recommendations.\n",
    "    Uses cosine similarity for semantic matching.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create embedding for the user profile\n",
    "        profile_embedding = embeddings.embed_query(profile)\n",
    "        \n",
    "        # Create embeddings for all course descriptions\n",
    "        course_texts = [f\"{title}: {desc}\" for title, desc in zip(titles, descriptions)]\n",
    "        course_embeddings = embeddings.embed_documents(course_texts)\n",
    "        \n",
    "        # Calculate cosine similarities\n",
    "        similarities = []\n",
    "        for i, (course_id, course_embedding) in enumerate(zip(course_ids, course_embeddings)):\n",
    "            if course_id not in completed_ids:\n",
    "                similarity = cosine_similarity([profile_embedding], [course_embedding])[0][0]\n",
    "                similarities.append((course_id, float(similarity)))\n",
    "        \n",
    "        # Sort by similarity score (descending) and return top 5\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        return similarities[:5]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in recommend_courses: {e}\")\n",
    "        return []\n",
    "\n",
    "# ======================================================\n",
    "# 7. Enhanced Pipeline Function\n",
    "# ======================================================\n",
    "def run_pipeline(question: str, completed_courses: List[str] = None) -> List[str]:\n",
    "    if completed_courses is None:\n",
    "        completed_courses = []\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Refine query\n",
    "        refined_query = query_refine_chain.run({\"question\": question}).strip()\n",
    "        print(f\"\\n Refined Query: {refined_query}\")\n",
    "\n",
    "        # Step 2: Retrieve context from vectorstore\n",
    "        docs = retriever.get_relevant_documents(refined_query)\n",
    "        context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "        # Step 3: Final recommendation\n",
    "        result = recommendation_chain.invoke({\n",
    "            \"question\": question,\n",
    "            \"completed_courses\": \", \".join(completed_courses) if completed_courses else \"None\",\n",
    "            \"context\": context,\n",
    "            \"format_instructions\": parser.get_format_instructions()\n",
    "        })\n",
    "\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error in run_pipeline: {e}\")\n",
    "        return []\n",
    "\n",
    "# ======================================================\n",
    "# 8. Evaluation Function\n",
    "# ======================================================\n",
    "def evaluate_recommendations():\n",
    "    \"\"\"Evaluate the recommendation engine with the 5 test profiles\"\"\"\n",
    "    test_profiles = [\n",
    "        (\"I've completed the 'Python Programming for Data Science' course and enjoy data visualization. What should I take next?\", [\"C001\"]),\n",
    "        (\"I know Azure basics and want to manage containers and build CI/CD pipelines. Recommend courses.\", []),\n",
    "        (\"My background is in ML fundamentals; I'd like to specialize in neural networks and production workflows.\", [\"C001\"]),\n",
    "        (\"I want to learn to build and deploy microservices with Kubernetes—what courses fit best?\", []),\n",
    "        (\"I'm interested in blockchain and smart contracts but have no prior experience. Which courses do you suggest?\", [])\n",
    "    ]\n",
    "    \n",
    "    print(\"=== EVALUATION REPORT ===\")\n",
    "    for i, (profile, completed) in enumerate(test_profiles, 1):\n",
    "        print(f\"\\n--- Test Profile {i} ---\")\n",
    "        print(f\"Input: {profile}\")\n",
    "        print(f\"Completed Courses: {completed}\")\n",
    "        \n",
    "        # Get vector similarity recommendations\n",
    "        vector_recs = recommend_courses(profile, completed)\n",
    "        print(\"Vector-based Recommendations (Course ID, Similarity Score):\")\n",
    "        for course_id, score in vector_recs:\n",
    "            # Find course title for better readability\n",
    "            course_index = course_ids.index(course_id) if course_id in course_ids else -1\n",
    "            course_title = titles[course_index] if course_index != -1 else \"Unknown Course\"\n",
    "            print(f\"  {course_id} - {course_title}: {score:.4f}\")\n",
    "        \n",
    "        # Get LLM-enhanced recommendations\n",
    "        try:\n",
    "            llm_recs = run_pipeline(profile, completed)\n",
    "            s = str(llm_recs['text'])\n",
    "            start = s.find(\"[\")\n",
    "            end = s.find(\"]\", start) + 1\n",
    "            if start != -1 and end != -1:\n",
    "                courses_list = ast.literal_eval(s[start:end])\n",
    "                print(\"LLM-enhanced Recommendations:\")\n",
    "                for course_id in courses_list:\n",
    "                    course_index = course_ids.index(course_id) if course_id in course_ids else -1\n",
    "                    course_title = titles[course_index] if course_index != -1 else \"Unknown Course\"\n",
    "                    print(f\"  {course_id} - {course_title}\")\n",
    "            else:\n",
    "                print(\"LLM-enhanced Recommendations: Could not parse output\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error in LLM recommendations: {e}\")\n",
    "        \n",
    "        print(\"\\nRelevance Comments: Both methods provide semantically relevant course recommendations.\")\n",
    "\n",
    "# ======================================================\n",
    "# 9. Example Run\n",
    "# ======================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Test the required function\n",
    "    test_profile = \"I've completed the 'Python Programming for Data Science' course and enjoy data visualization.\"\n",
    "    test_completed = [\"C001\"]  # Example completed course ID\n",
    "    \n",
    "    print(\"=== Testing recommend_courses function ===\")\n",
    "    recommendations = recommend_courses(test_profile, test_completed)\n",
    "    print(\"Top 5 recommendations with similarity scores:\")\n",
    "    for course_id, score in recommendations:\n",
    "        course_index = course_ids.index(course_id) if course_id in course_ids else -1\n",
    "        course_title = titles[course_index] if course_index != -1 else \"Unknown Course\"\n",
    "        print(f\"  {course_id} - {course_title}: {score:.4f}\")\n",
    "    \n",
    "    # Run evaluation\n",
    "    evaluate_recommendations()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
